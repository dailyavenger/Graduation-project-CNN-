{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnbIaWdHTFuC"
      },
      "source": [
        "### 이 파일이 이미지로 점수 예측하는 코드입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsLThwa3wzCn"
      },
      "source": [
        "# 0. 실행할 부분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5uikNndWW_9T"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nfs/home/dailyavenger/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#목표: 몇페이지가 영향력 있는지\n",
        "\n",
        "# torchvision 관련 라이브러리 import\n",
        "\n",
        "from torchvision import utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x8E-xwbW_Qt",
        "outputId": "8524635b-89fb-44b1-e667-3b54bf543672"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3gRUgpEW9cq",
        "outputId": "9d0a8001-ff71-48eb-b4cb-8554ca0d5d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonlines in ./.local/lib/python3.9/site-packages (3.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3/dist-packages (from jsonlines) (20.3.0)\n",
            "Requirement already satisfied: pdf2image in ./.local/lib/python3.9/site-packages (1.16.0)\n",
            "Requirement already satisfied: pillow in ./.local/lib/python3.9/site-packages (from pdf2image) (9.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install jsonlines\n",
        "!pip install pdf2image  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0wgRUMyyW9je"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XW5zuXp1W9nc"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import jsonlines\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq9kUAavw9Gi"
      },
      "source": [
        "#1. 데이터셋 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xw36Jb0yW9s-"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import cv2\n",
        "\n",
        "class PaperDataSet(Dataset):\n",
        "    def __init__(self, overall_image_path, transform=None):\n",
        "        print(\"initialize data sets\")\n",
        "        self.transform = transform\n",
        "        rating_dict = {}\n",
        "        self.image_list = list()\n",
        "        self.score_list = list()\n",
        "        years = [\"2021\"]\n",
        "        lst_ = [ \"UH-cmocLJC\", \"mNtmhaDkAr\",  \"UiLl8yjh57\",  \"kB8DkEKSDH\", \"cL4wkyoxyDJ\"]\n",
        "        for year in years:\n",
        "            cnt = 0\n",
        "            year_image_path = overall_image_path\n",
        "            # year_image_path = overall_image_path+\"iclr\"+year+\"/\"\n",
        "            # *********** 경로 수정 ***********\n",
        "            with jsonlines.open(f\"iclr{year}_metadata.jsonl\") as read_file:\n",
        "                for line in read_file.iter():\n",
        "                    rating_dict[line['forum']] = line['rating']\n",
        "            input_paths = os.listdir(year_image_path)\n",
        "            for one_file_image_path in tqdm(input_paths, desc=\"make data set\"):\n",
        "                if one_file_image_path not in lst_:\n",
        "                  image_path = year_image_path + one_file_image_path + \"/\"\n",
        "                  before_add_size = len(self.image_list)\n",
        "                  self.image_list.extend(glob.glob(image_path + \"9.bin\")) # glob: 폴더 내의 파일 찾아줌\n",
        "                  rating = rating_dict[one_file_image_path]\n",
        "                  self.score_list.extend([rating] * (len(self.image_list)-before_add_size))\n",
        "                  cnt += len(self.image_list)-before_add_size\n",
        "                else:\n",
        "                  print(one_file_image_path, \"is in lst_\")\n",
        "            print(f\"{year}: {cnt}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_list[idx]\n",
        "        label = self.score_list[idx]\n",
        "        binary_file = image_path   # binary_file = dataset/image/iclr2021/_0kaDkv3dVf/3.bin \n",
        "        with open(binary_file, 'rb') as f:\n",
        "            data = f.read()\n",
        "        encoded_img = np.fromstring(data, dtype=np.uint8)\n",
        "        img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR) \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        \n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cSfWpocEW9xt"
      },
      "outputs": [],
      "source": [
        "image_path =  \"../wngusrud27/dataset/image/iclr2021/\" \n",
        "image_path2 =  \"temp/\" \n",
        "dataset_file_name = 'iclr2021_dataset.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Op-IvCLdxQAD"
      },
      "outputs": [],
      "source": [
        "#zip_path = image_path + \"iclr2021_binary.zip\"\n",
        "\n",
        "#!mkdir binary\n",
        "\n",
        "#!cp {zip_path} ./iclr2021.zip\n",
        "\n",
        "#!unzip -q ./iclr2021.zip -d ./binary/ \n",
        "\n",
        "#!rm ./iclr2021.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cgKR9l_DXcJ6"
      },
      "outputs": [],
      "source": [
        "def make_save_data_set(image_path2, dataset_file_name):\n",
        "  print(\"start to make data set\")\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "  dataset = PaperDataSet(image_path, transform=transform)\n",
        "  print(f\"data set length: {dataset.__len__()}\")\n",
        "\n",
        "  torch.save(dataset, image_path2 + dataset_file_name)\n",
        "  print(\"save data sets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt1_lnn8XcMi",
        "outputId": "1c57eee0-2be1-4be8-93ba-45e227f5cddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start to make data set\n",
            "initialize data sets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "make data set:  22%|██▏       | 572/2594 [00:00<00:00, 5707.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kB8DkEKSDH is in lst_\n",
            "UiLl8yjh57 is in lst_\n",
            "mNtmhaDkAr is in lst_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "make data set:  45%|████▍     | 1166/2594 [00:00<00:00, 5843.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UH-cmocLJC is in lst_\n",
            "cL4wkyoxyDJ is in lst_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "make data set: 100%|██████████| 2594/2594 [00:00<00:00, 5898.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021: 2589\n",
            "data set length: 2589\n",
            "save data sets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#image_path =  \"./binary/\" \n",
        "make_save_data_set(image_path2, dataset_file_name)\n",
        "# data_set_usage_ex(dataset_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEqyEffNZy6k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WjyhkPoaxNj",
        "outputId": "6f0f6ae7-cb39-4278-b73a-e611857b9fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train size: 18675\n",
            "test size: 4671\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "dataset = torch.load(dataset_file_name)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "print(\"train size:\", train_size-1)\n",
        "\n",
        "test_size = len(dataset) - train_size\n",
        "print(\"test size:\", test_size+1)\n",
        "# validation \n",
        "train_dataset, test_dataset = random_split(dataset, [train_size-1,test_size+1])\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvjr_4qUNeYW"
      },
      "source": [
        "# 2 모델 생성,하이퍼 파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_UegSgy0NMSS"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=False).to(device) # true 옵션으로 사전 학습된 모델을 로드\n",
        "\n",
        "# transfer learning 사용 시 추가 \n",
        "# if using_transfer_learning:|\n",
        "#   for param in resnet50.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "model = nn.Sequential(\n",
        "    resnet50,\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(1000, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1)\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KaZHNA_HNk7b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "lr = 0.0001\n",
        "num_epochs = 5\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "loss_function = nn.MSELoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9CHLTVscNqcv"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'num_epochs':num_epochs,\n",
        "    'optimizer':optimizer,\n",
        "    'loss_function':loss_function,\n",
        "    'train_dataloader':train_dataloader,\n",
        "    'test_dataloader': test_dataloader,\n",
        "    'device':device\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqYfFv_KknpU"
      },
      "source": [
        "# 3. 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3HgavN8RgIgR"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zWBymtOu8a8E"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "from numpy import vstack\n",
        "\n",
        "def train(model, params):\n",
        "  total_start = time.time()\n",
        "  loss_function=params[\"loss_function\"]\n",
        "  train_dataloader=params[\"train_dataloader\"]\n",
        "  test_dataloader=params[\"test_dataloader\"]\n",
        "  device=params[\"device\"]\n",
        "\n",
        "  print(\"start train\")\n",
        "  #print(\"train size:\", train_size-1)\n",
        "    #print(\"test size:\", test_size+1)\n",
        "  for epoch in range(0, num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    epoch_start = time.time()\n",
        "    trained_number = 0\n",
        "    i2=0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "      i2=i\n",
        "          \n",
        "        # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.type(torch.FloatTensor) \n",
        "      labels = labels.to(device)\n",
        "        \n",
        "        # 이전 batch에서 계산된 가중치를 초기화\n",
        "      optimizer.zero_grad() \n",
        "        # forward + back propagation 연산\n",
        "      outputs = model(inputs).squeeze()\n",
        "      train_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32))\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "      trained_number += labels.size(0)\n",
        "        \n",
        "        #if i%100==0:\n",
        "          #print(f\"epoch {epoch+1} {trained_number/train_size*100*9}% train finish\")\n",
        "      #print(f\"epoch {epoch+1} train finish\") \n",
        "\n",
        "    \n",
        "\n",
        "    model.eval()\n",
        "      # test accuracy 계산\n",
        "      \n",
        "      \n",
        "    total=0\n",
        "    correct=0\n",
        "    correct2=0\n",
        "    loss=0\n",
        "    for i, data in enumerate(test_dataloader, 0):\n",
        "      i2=i\n",
        "         \n",
        "        \n",
        "      inputs, labels = data        \n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.type(torch.FloatTensor) \n",
        "      labels = labels.to(device)\n",
        "        \n",
        "\n",
        "        # 결과값 연산\n",
        "      outputs = model(inputs).squeeze()\n",
        "      i_batch_size = labels.size(0)\n",
        "      total += i_batch_size\n",
        "      correct += (abs(outputs - labels)<0.5).sum().item() # 변경될 수 있음 \n",
        "      correct2 += (abs(outputs - labels)).sum().item()\n",
        "      test_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32)).item()\n",
        "      loss += i_batch_size * test_loss\n",
        "        #if i%50==0:\n",
        "          #print(f\"epoch {epoch+1} {total/test_size*100*9}% test finish\")\n",
        "        # break\n",
        "    \n",
        "\n",
        "        # 학습 결과 출력\n",
        "      #print(f\"{epoch+1} pages amount: {i2}\")\n",
        "      \n",
        "     \n",
        "    print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f, difference: %.6f' %(epoch+1, num_epochs, train_loss.item(), loss/total, 100*correct/total, correct2/total)) #, correct2/total\n",
        "    \n",
        "      \n",
        "      #epoch_elapsed_time = time.time() - epoch_start\n",
        "      #epoch_elapsed_time_list = str(datetime.timedelta(seconds=epoch_elapsed_time)).split(\".\")\n",
        "      #total_elapsed_time = time.time() - total_start\n",
        "      #total_elapsed_time_list = str(datetime.timedelta(seconds=total_elapsed_time)).split(\".\")\n",
        "      #print(f\"Epoch {epoch+1} Elapsed time is {epoch_elapsed_time_list[0]}\")  \n",
        "      #print(f\"Total Elapsed time is {total_elapsed_time_list[0]}\")  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-0RVcRz9hyd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmAGMDr2Nqhv",
        "outputId": "07a671f2-afa7-4d40-a140-07836aa98218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2322661/2827642708.py:44: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  encoded_img = np.fromstring(data, dtype=np.uint8)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/5, Train loss: 0.399041, Test loss: 0.574899, Accuracy: 53.65, difference: 0.574436\n",
            "Epoch: 2/5, Train loss: 0.696491, Test loss: 0.678065, Accuracy: 44.04, difference: 0.667145\n",
            "Epoch: 3/5, Train loss: 0.699149, Test loss: 0.630404, Accuracy: 45.49, difference: 0.640518\n",
            "Epoch: 4/5, Train loss: 0.482009, Test loss: 0.509339, Accuracy: 53.86, difference: 0.556394\n",
            "Epoch: 5/5, Train loss: 0.462001, Test loss: 0.502315, Accuracy: 54.96, difference: 0.546535\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()              \n",
        "torch.cuda.empty_cache()\n",
        "train(model, params) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ilaHF08p9iqv",
        "outputId": "9052e59e-faaf-405d-cc85-dc61502f7cbf"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3083572999.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Input \u001b[0;32mIn [17]\u001b[0;36m\u001b[0m\n\u001b[0;31m    +=1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "+=1\n",
        "#torch.save(model.state_dict(), \"temp/model1\" )\n",
        "\n",
        "#torch.save(model, \"temp2/model2\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc7CClaJ92H_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpygeWT-F2Nb"
      },
      "source": [
        "## 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRniceI5F31-"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import cv2\n",
        "class TestDataSet(Dataset):\n",
        "    def __init__(self, overall_image_path, transform=None):\n",
        "        print(\"initialize data sets\")\n",
        "        self.transform = transform\n",
        "        rating_dict = {}\n",
        "        self.image_list = list()\n",
        "        self.score_list = list()\n",
        "        cnt = 0\n",
        "        year_image_path = overall_image_path\n",
        "        # year_image_path = overall_image_path+\"iclr\"+year+\"/\"\n",
        "        with jsonlines.open(f\"drive/Shareddrives/소종-논문/iclr2021_metadata.jsonl\") as read_file:\n",
        "            for line in read_file.iter():\n",
        "                rating_dict[line['forum']] = line['rating']\n",
        "        input_paths = os.listdir(year_image_path)\n",
        "        input_paths.sort()\n",
        "        for one_file_image_path in tqdm(input_paths, desc=\"make data set\"):\n",
        "            image_path = year_image_path + one_file_image_path + \"/\"\n",
        "            before_add_size = len(self.image_list)\n",
        "            imgs = glob.glob(image_path + \"1.bin\")\n",
        "            imgs.sort()\n",
        "            self.image_list.extend(imgs) # glob: 폴더 내의 파일 찾아줌\n",
        "            rating = rating_dict[one_file_image_path]\n",
        "            self.score_list.extend([rating] * (len(self.image_list)-before_add_size))\n",
        "            cnt += len(self.image_list)-before_add_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_list[idx]\n",
        "        label = self.score_list[idx]\n",
        "        binary_file = image_path   # binary_file = dataset/image/iclr2021/_0kaDkv3dVf/3.bin \n",
        "        with open(binary_file, 'rb') as f:\n",
        "            data = f.read()\n",
        "        encoded_img = np.fromstring(data, dtype=np.uint8)\n",
        "        img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR) \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def img_list(self):\n",
        "      print(self.image_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PDBRIS7F34A"
      },
      "outputs": [],
      "source": [
        "image_path = \"drive/Shareddrives/소종-논문/test/binary/occlusion/\" \n",
        "dataset_file_name = 'iclr2021_dataset_test.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofxU100mF36Z"
      },
      "outputs": [],
      "source": [
        "def test_make_save_data_set(image_path, dataset_file_name):\n",
        "  print(\"start to make data set\")\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "  dataset = TestDataSet(image_path, transform=transform)\n",
        "  print(f\"data set length: {dataset.__len__()}\")\n",
        "\n",
        "  torch.save(dataset, dataset_file_name)\n",
        "  print(\"save data sets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2yUeA3f9kGd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huVmvsZgF38Y",
        "outputId": "271add82-0b93-4286-a2a0-0d17052d1a3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start to make data set\n",
            "initialize data sets\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'drive/Shareddrives/소종-논문/iclr2021_metadata.jsonl'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/nfs/home/dailyavenger/0521.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000032vscode-remote?line=0'>1</a>\u001b[0m test_make_save_data_set(image_path, dataset_file_name)\n",
            "\u001b[1;32m/nfs/home/dailyavenger/0521.ipynb Cell 31'\u001b[0m in \u001b[0;36mtest_make_save_data_set\u001b[0;34m(image_path, dataset_file_name)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000030vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mstart to make data set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000030vscode-remote?line=2'>3</a>\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000030vscode-remote?line=3'>4</a>\u001b[0m     transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000030vscode-remote?line=4'>5</a>\u001b[0m ])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000030vscode-remote?line=6'>7</a>\u001b[0m dataset \u001b[39m=\u001b[39m TestDataSet(image_path, transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000030vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata set length: \u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m.\u001b[39m\u001b[39m__len__\u001b[39m()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000030vscode-remote?line=9'>10</a>\u001b[0m torch\u001b[39m.\u001b[39msave(dataset, dataset_file_name)\n",
            "\u001b[1;32m/nfs/home/dailyavenger/0521.ipynb Cell 29'\u001b[0m in \u001b[0;36mTestDataSet.__init__\u001b[0;34m(self, overall_image_path, transform)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000028vscode-remote?line=10'>11</a>\u001b[0m year_image_path \u001b[39m=\u001b[39m overall_image_path\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000028vscode-remote?line=11'>12</a>\u001b[0m \u001b[39m# year_image_path = overall_image_path+\"iclr\"+year+\"/\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000028vscode-remote?line=12'>13</a>\u001b[0m \u001b[39mwith\u001b[39;00m jsonlines\u001b[39m.\u001b[39;49mopen(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdrive/Shareddrives/소종-논문/iclr2021_metadata.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m read_file:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000028vscode-remote?line=13'>14</a>\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m read_file\u001b[39m.\u001b[39miter():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000028vscode-remote?line=14'>15</a>\u001b[0m         rating_dict[line[\u001b[39m'\u001b[39m\u001b[39mforum\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m line[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py:623\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(file, mode, loads, dumps, compact, sort_keys, flush)\u001b[0m\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py?line=620'>621</a>\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m Reader \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m Writer\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py?line=621'>622</a>\u001b[0m encoding \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mutf-8-sig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py?line=622'>623</a>\u001b[0m fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(file, mode\u001b[39m=\u001b[39;49mmode \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mt\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py?line=623'>624</a>\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py?line=624'>625</a>\u001b[0m     loads\u001b[39m=\u001b[39mloads,\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py?line=625'>626</a>\u001b[0m     dumps\u001b[39m=\u001b[39mdumps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py?line=628'>629</a>\u001b[0m     flush\u001b[39m=\u001b[39mflush,\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py?line=629'>630</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/jsonlines/jsonlines.py?line=630'>631</a>\u001b[0m kwargs \u001b[39m=\u001b[39m {key: value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/Shareddrives/소종-논문/iclr2021_metadata.jsonl'"
          ]
        }
      ],
      "source": [
        "test_make_save_data_set(image_path, dataset_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crqiq-0BF3-V",
        "outputId": "43ad5bca-7c7b-4e7a-f05b-b7c6e2029e76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nfs/home/dailyavenger/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/nfs/home/dailyavenger/0521.ipynb Cell 34'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000033vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m random_split\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000033vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdset\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000033vscode-remote?line=3'>4</a>\u001b[0m dataset \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(dataset_file_name)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000033vscode-remote?line=5'>6</a>\u001b[0m test_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataset)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0521.ipynb#ch0000033vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest size:\u001b[39m\u001b[39m\"\u001b[39m, test_size)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "dataset = torch.load(dataset_file_name)\n",
        "\n",
        "test_size = len(dataset)\n",
        "print(\"test size:\", test_size)\n",
        "# validation \n",
        "\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-zjIOU1F4Ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgRShB7jF4Cm"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "from numpy import vstack\n",
        "\n",
        "def test(model, params):\n",
        "    total_start = time.time()\n",
        "    loss_function=params[\"loss_function\"]\n",
        "    test_dataloader=dataloader\n",
        "    device=params[\"device\"]\n",
        "\n",
        "    print(\"start train\")\n",
        "    print(\"test size:\", test_size)\n",
        "\n",
        "    # test accuracy 계산\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss = 0\n",
        "    model.eval()\n",
        "    \n",
        "    for i, data in enumerate(test_dataloader, 0):\n",
        "      print(\"i:\", i)\n",
        "      \n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.type(torch.FloatTensor) \n",
        "      labels = labels.to(device)\n",
        "\n",
        "      print(\"size:\",labels.size(0))\n",
        "      print(\"label:\", labels)\n",
        "      \n",
        "\n",
        "      # 결과값 연산\n",
        "      outputs = model(inputs).squeeze()\n",
        "      print(\"output:\", outputs)\n",
        "      i_batch_size = labels.size(0)\n",
        "      total += i_batch_size\n",
        "      correct += (abs(outputs - labels)<0.5).sum().item() # 변경될 수 있음 \n",
        "      test_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32)).item()\n",
        "      loss += i_batch_size * test_loss\n",
        "\n",
        "      # 학습 결과 출력\n",
        "    print('Test loss: %.6f, Accuracy: %.2f' %(loss/total, 100*correct/total))\n",
        "\n",
        "    total_elapsed_time = time.time() - total_start\n",
        "    total_elapsed_time_list = str(datetime.timedelta(seconds=total_elapsed_time)).split(\".\")\n",
        "    print(f\"Total Elapsed time is {total_elapsed_time_list[0]}\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOfSetI1F4Ew",
        "outputId": "dc92c833-8d06-4c79-a096-a1876d93d8af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start train\n",
            "test size: 45\n",
            "i: 0\n",
            "size: 32\n",
            "label: tensor([8.7500, 8.7500, 8.7500, 8.7500, 8.7500, 8.7500, 8.7500, 8.7500, 8.7500,\n",
            "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
            "        2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000,\n",
            "        4.0000, 4.0000, 4.0000, 4.0000, 4.0000], device='cuda:0')\n",
            "output: tensor([6.5816, 6.5845, 6.5476, 6.7172, 6.5774, 6.7502, 6.5787, 6.6212, 6.6677,\n",
            "        5.2512, 4.5495, 5.4114, 5.3056, 5.1830, 4.2590, 5.1306, 4.4159, 5.0974,\n",
            "        4.9216, 4.9011, 4.5559, 5.0236, 4.7439, 5.2108, 4.7982, 5.3017, 4.9362,\n",
            "        4.7339, 4.6832, 5.0069, 4.9728, 4.8730], device='cuda:0',\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i: 1\n",
            "size: 13\n",
            "label: tensor([4., 4., 4., 4., 7., 7., 7., 7., 7., 7., 7., 7., 7.], device='cuda:0')\n",
            "output: tensor([5.2232, 4.7544, 4.4490, 4.9124, 6.6159, 6.6060, 6.7244, 6.4929, 6.6800,\n",
            "        6.5359, 6.5436, 6.2699, 6.6201], device='cuda:0',\n",
            "       grad_fn=<SqueezeBackward0>)\n",
            "Test loss: 2.917464, Accuracy: 31.11\n",
            "Total Elapsed time is 0:00:00\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "test(model, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olgosH4f-cnH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ofBofdF0Cl"
      },
      "source": [
        "## 안쓰는 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zxw_uyDk52_"
      },
      "outputs": [],
      "source": [
        "lst = list()\n",
        "with jsonlines.open(\"iclr2021_metadata.jsonl\") as read_file:\n",
        "  for line in read_file.iter():\n",
        "    lst.append(float(line['rating']))\n",
        "avg = sum(lst)/len(lst)\n",
        "print(avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbnsurcjCaHp"
      },
      "outputs": [],
      "source": [
        "avg_lst = [avg] * len(lst)\n",
        "loss_function = nn.MSELoss()\n",
        "test_loss = loss_function(torch.Tensor(lst).to(torch.float32), torch.Tensor(avg_lst).to(torch.float32)).item()\n",
        "print(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddCq-3vtBYkJ"
      },
      "outputs": [],
      "source": [
        "total = 0\n",
        "loss = 0\n",
        "for i, data in enumerate(test_dataloader, 0):\n",
        "  inputs, labels = data\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.type(torch.FloatTensor) \n",
        "  labels = labels.to(device)\n",
        "  \n",
        "  i_batch_size = labels.size(0)\n",
        "  outputs = [avg] * i_batch_size\n",
        "  outputs = torch.Tensor(outputs).to(device)\n",
        "  total += i_batch_size\n",
        "  test_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32)).item()\n",
        "  loss += i_batch_size * test_loss\n",
        "\n",
        "print('loss: %.6f' %(loss/total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gxavH25CBz3"
      },
      "outputs": [],
      "source": [
        " from torchvision import models\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=True) # true 옵션으로 사전 학습된 모델을 로드\n",
        "\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model2 = nn.Sequential(\n",
        "    resnet50,\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(1000, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1)\n",
        ").to(device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0519_capstone_resnet50 (1).ipynb의 사본",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
