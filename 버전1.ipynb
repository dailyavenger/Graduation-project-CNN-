{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0516_산키님_채널_코드_수정.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Transfer Learning Model for Capstone Project </h1>"
      ],
      "metadata": {
        "id": "0uhYs2TvfOEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading weights related to ImageNet for ResNet50:"
      ],
      "metadata": {
        "id": "FYK1k838fDin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 파일을 기준으로 서버에 올려주세요! "
      ],
      "metadata": {
        "id": "KbfoTKhOJU1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgWhxgBUYsbF",
        "outputId": "b67bb4ff-c210-4570-fd79-908c4960faea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines\n",
        "!pip install openreview-py\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "aj2bE9J0Zgck",
        "outputId": "5129040c-956f-45f5-d52c-63a4619a49e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (4.2.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.4.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-3.0.0\n",
            "Collecting openreview-py\n",
            "  Downloading openreview_py-1.2.3-py2.py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from openreview-py) (2.23.0)\n",
            "Collecting pylatexenc\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 76.0 MB/s \n",
            "\u001b[?25hCollecting tld>=0.12\n",
            "  Downloading tld-0.12.6-py37-none-any.whl (412 kB)\n",
            "\u001b[K     |████████████████████████████████| 412 kB 64.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from openreview-py) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openreview-py) (4.64.0)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting pyjwt\n",
            "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
            "Collecting setuptools==49.6.0\n",
            "  Downloading setuptools-49.6.0-py3-none-any.whl (803 kB)\n",
            "\u001b[K     |████████████████████████████████| 803 kB 61.5 MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->openreview-py) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->openreview-py) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->openreview-py) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->openreview-py) (3.0.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->openreview-py) (1.14.0)\n",
            "Building wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136835 sha256=91c4d3accf6a7eb5a7cb269174f190c1506df893494e0a2b5df678b7f662e506\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/8a/f5/33ee79d4473eb201b519fa40f989b842e373237395a3421f52\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: tld, setuptools, pylatexenc, pyjwt, pycryptodome, Deprecated, openreview-py\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Deprecated-1.2.13 openreview-py-1.2.3 pycryptodome-3.14.1 pyjwt-2.4.0 pylatexenc-2.10 setuptools-49.6.0 tld-0.12.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pdf2image) (7.1.2)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9yNaUDwF-S9"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The custom Model that we would be using for the project:"
      ],
      "metadata": {
        "id": "AXEVhf4ve5hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(one, two):\n",
        "  return ((one - two) ** 2).mean()\n",
        "  \n",
        "def rms(one, two):\n",
        "  return np.sqrt(mse(one, two))"
      ],
      "metadata": {
        "id": "9esQ-D6oeyMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Data Preperation </h1>"
      ],
      "metadata": {
        "id": "E9GaQF5Gm-U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "import openreview\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import jsonlines\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import gc"
      ],
      "metadata": {
        "id": "iJzHw7wEdr9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import jsonlines\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class PaperChannelDataSet(Dataset):\n",
        "    def __init__(self, overall_image_path, transform=None):\n",
        "        print(\"initialize data sets\")\n",
        "        self.transform = transform\n",
        "        rating_dict = {}\n",
        "        self.paper_path_list = list()\n",
        "        self.score_list = list()\n",
        "        years = [\"2021\"]\n",
        "        for year in years:\n",
        "            year_image_path = overall_image_path+\"iclr\"+year+\"/\"\n",
        "            with jsonlines.open(f\"iclr{year}_metadata.jsonl\") as read_file:\n",
        "                for line in read_file.iter():\n",
        "                    rating_dict[line['forum']] = line['rating']\n",
        "            input_paths = os.listdir(year_image_path)\n",
        "            for one_file_image_path in tqdm(input_paths, desc=\"make data set\"):\n",
        "                paper_path = year_image_path + one_file_image_path + \"/\"\n",
        "                self.paper_path_list.append(paper_path)\n",
        "                rating = rating_dict[one_file_image_path]\n",
        "                self.score_list.append(rating)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paper_path_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        lst = list()\n",
        "        paper_path = self.paper_path_list[idx]  # paper_path : dataset/image/iclr2021/_0kaDkv3dVf/\n",
        "        label = self.score_list[idx]\n",
        "        for i in range(9):\n",
        "            binary_file = f\"{paper_path}{i+1}.bin\"   # binary_file = dataset/image/iclr2021/_0kaDkv3dVf/3.bin \n",
        "            with open(binary_file, 'rb') as f:\n",
        "                data = f.read()\n",
        "            encoded_img = np.fromstring(data, dtype=np.uint8)\n",
        "            img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR) \n",
        "            if self.transform is not None:\n",
        "                img = self.transform(img)\n",
        "            lst.append(img) \n",
        "        tensor = torch.cat(lst, 0) \n",
        "        return tensor, label"
      ],
      "metadata": {
        "id": "QwaDHxd0R-GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path =  \"drive/Shareddrives/소종-논문/test/\" \n",
        "dataset_file_name = 'iclr2021_dataset.pt'"
      ],
      "metadata": {
        "id": "YegzQF0DZC8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_save_data_set(image_path, dataset_file_name):\n",
        "  print(\"start to make data set\")\n",
        "  transform = transforms.Compose([\n",
        "      # transforms.Resize((224, 224)),\n",
        "      transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "  dataset = PaperChannelDataSet(image_path, transform=transform)\n",
        "  print(f\"data set length: {dataset.__len__()}\")\n",
        "\n",
        "  torch.save(dataset, image_path + dataset_file_name)\n",
        "  print(\"save data sets\")"
      ],
      "metadata": {
        "id": "26NXyv74dmPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_save_data_set(image_path, dataset_file_name)"
      ],
      "metadata": {
        "id": "1OuVeYQIdleD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e154a2-116b-4117-82e6-d755fdee2ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start to make data set\n",
            "initialize data sets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "make data set: 100%|██████████| 56/56 [00:00<00:00, 131072.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data set length: 56\n",
            "save data sets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.load(image_path + dataset_file_name)\n",
        "dataloader = DataLoader(dataset)"
      ],
      "metadata": {
        "id": "FYtZzVTDW8V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Training and Testing </h1>"
      ],
      "metadata": {
        "id": "v3lrqESUYlKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "dataset = torch.load(image_path + dataset_file_name)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "print(\"train size:\", train_size)\n",
        "\n",
        "test_size = len(dataset) - train_size\n",
        "print(\"test size:\", test_size)\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size,test_size])\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "9GsCEXMkT70F",
        "outputId": "f35369a4-0b5e-4483-f8be-d3d7d94f833d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size: 44\n",
            "test size: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_channel, using_transfer_learning=True):\n",
        "  assert(input_channel % 3 == 0, \"The number of channels needs to be a multiple of 3\")\n",
        "\n",
        "  resnet50 = models.resnet50(pretrained=using_transfer_learning).to(device)\n",
        "\n",
        "  if input_channel != 3:\n",
        "    old_layer = resnet50.conv1\n",
        "    \n",
        "    # Creating a new Conv2d layer\n",
        "    new_layer = nn.Conv2d(in_channels=input_channel, # 3 -> input_channel\n",
        "                      out_channels=old_layer.out_channels, # 64\n",
        "                      kernel_size=old_layer.kernel_size, # (7, 7)\n",
        "                      stride=old_layer.stride, # (2, 2)\n",
        "                      padding=old_layer.padding, # (3, 3)\n",
        "                      bias=old_layer.bias) # False\n",
        "\n",
        "    if using_transfer_learning:\n",
        "      for channel in range(3, input_channel, 3):\n",
        "        new_layer.weight[:, channel:channel+3, :, :] = old_layer.weight[:, 0:3, : :].clone()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # Copying the weights from the old to the new layer\n",
        "      new_layer.weight[:, 0:3, :, :] = old_layer.weight.clone()\n",
        "      \n",
        "    new_layer.weight = nn.Parameter(new_layer.weight, requires_grad=(not using_transfer_learning))\n",
        "  \n",
        "    resnet50.conv1 = new_layer\n",
        "\n",
        "  if using_transfer_learning:\n",
        "    for param in resnet50.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  model = nn.Sequential(\n",
        "      resnet50,\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(1000, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256, 32),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(32, 1)\n",
        "  ).to(device)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "gYwQIhgGemm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35ea218-f978-4cd6-b798-2844d92103f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-b097515042bf>:2: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert(input_channel % 3 == 0, \"The number of channels needs to be a multiple of 3\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height, input_channel = 224, 224, 27\n",
        "\n",
        "non_transfer_learning_model = create_model(input_channel, using_transfer_learning=False)\n",
        "\n",
        "print(non_transfer_learning_model.eval())"
      ],
      "metadata": {
        "id": "oMx6BXTSfFTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e75facd-a820-4c61-a319-c9894eeaec7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): ResNet(\n",
            "    (conv1): Conv2d(27, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "  )\n",
            "  (1): Flatten(start_dim=1, end_dim=-1)\n",
            "  (2): Linear(in_features=1000, out_features=256, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=256, out_features=32, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(non_transfer_learning_model, (27, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FfEkrzFyS3k",
        "outputId": "f2cabf60-1af0-45d1-a601-0c1195170cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          84,672\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "          ResNet-175                 [-1, 1000]               0\n",
            "         Flatten-176                 [-1, 1000]               0\n",
            "          Linear-177                  [-1, 256]         256,256\n",
            "            ReLU-178                  [-1, 256]               0\n",
            "          Linear-179                   [-1, 32]           8,224\n",
            "            ReLU-180                   [-1, 32]               0\n",
            "          Linear-181                    [-1, 1]              33\n",
            "================================================================\n",
            "Total params: 25,896,809\n",
            "Trainable params: 25,896,809\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 5.17\n",
            "Forward/backward pass size (MB): 286.58\n",
            "Params size (MB): 98.79\n",
            "Estimated Total Size (MB): 390.53\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(non_transfer_learning_model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "_blS_G4RsvB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(param.numel() for param in non_transfer_learning_model.parameters() if param.requires_grad)\n",
        "print(total_params)"
      ],
      "metadata": {
        "id": "qj_BxoGVe_Fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9db5df0-a8a0-4fb1-88a2-c295ac2dfdcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25896809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "from numpy import vstack\n",
        "\n",
        "all_test_losses = []\n",
        "\n",
        "def getLoss(pred, labels):\n",
        "  return loss_fn(pred.to(torch.float32), labels.to(torch.float32))\n",
        "\n",
        "def train():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # loss_function=loss_fn\n",
        "\n",
        "    print(\"start train\")\n",
        "    print(\"train size:\", train_size)\n",
        "    print(\"test size:\", test_size)\n",
        "\n",
        "    trained_number = 0\n",
        "    training_loss = 0\n",
        "    total_start = time.time()\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "      epoch_start = time.time()\n",
        "\n",
        "      for i, data in enumerate(train_dataloader):\n",
        "        # i_start = time.time()\n",
        "        \n",
        "        # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.type(torch.LongTensor) \n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # process_time = time.time()\n",
        "\n",
        "        # 이전 batch에서 계산된 가중치를 초기화\n",
        "        optimizer.zero_grad() \n",
        "        # forward + back propagation 연산\n",
        "        outputs = non_transfer_learning_model(inputs).squeeze()\n",
        "        \n",
        "        # i_loss = time.time()\n",
        "\n",
        "        # train_loss = loss_fn(outputs.to(torch.float32), labels.to(torch.float32))\n",
        "        train_loss = getLoss(outputs, labels)\n",
        "\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        training_loss += train_loss.item()\n",
        "        trained_number += labels.size(0)\n",
        "\n",
        "        # i_end = time.time()\n",
        "\n",
        "        # print(\"process_time:\", process_time - i_start, \"pred_time:\", i_loss - process_time,\"loss_time:\",i_end - i_loss)\n",
        "        \n",
        "        # if i % 20 == 0:\n",
        "        #   print(\"i is:\", i)\n",
        "        \n",
        "        if i % 50 == 0:\n",
        "          print(f\"epoch {epoch}: {(trained_number/train_size)*100}% train finish\")\n",
        "        # break\n",
        "    \n",
        "      print(f\"epoch {epoch} train finish\")\n",
        "      # test accuracy 계산\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      # test_loss_list = list()\n",
        "      test_loss_total = 0\n",
        "\n",
        "      for i, data in enumerate(test_dataloader):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 결과값 연산\n",
        "        outputs = non_transfer_learning_model(inputs).squeeze()\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (abs(outputs - labels)<0.5).sum().item()\n",
        "        # test_loss = loss_fn(outputs.to(torch.float32), labels.to(torch.float32)).item()\n",
        "        test_loss = getLoss(outputs, labels)\n",
        "\n",
        "        # test_loss_list.append(test_loss)\n",
        "        test_loss_total += test_loss\n",
        "\n",
        "        all_test_losses.append(test_loss)\n",
        "        \n",
        "        # Calculating random MSE:\n",
        "\n",
        "        if i%20==0:\n",
        "          print(f\"epoch {epoch} {total/test_size*100}% test finish\")\n",
        "        # break\n",
        "\n",
        "      # 학습 결과 출력\n",
        "      # print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch, num_epochs, train_loss.item(), sum(test_loss_list)/len(test_loss_list), 100*correct/total))\n",
        "      print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch, num_epochs, train_loss.item(), test_loss_total/labels.size(0), 100*correct/total))\n",
        "\n",
        "      epoch_elapsed_time = time.time() - epoch_start\n",
        "      epoch_elapsed_time_list = str(datetime.timedelta(seconds=epoch_elapsed_time)).split(\".\")\n",
        "      total_elapsed_time = time.time() - total_start\n",
        "      total_elapsed_time_list = str(datetime.timedelta(seconds=total_elapsed_time)).split(\".\")\n",
        "      print(f\"Epoch {epoch} Elapsed time is {epoch_elapsed_time_list[0]}\")  \n",
        "      print(f\"Total Elapsed time is {total_elapsed_time_list[0]}\")  "
      ],
      "metadata": {
        "id": "6c2SRoZEaNtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "\n",
        "all_test_losses = []\n",
        "\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhMhjCw5jEjY",
        "outputId": "7cc78497-8ce2-4aaf-98a8-9530af12ada1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start train\n",
            "train size: 44\n",
            "test size: 12\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "epoch 1: 36.36363636363637% train finish\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "epoch 1 train finish\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "img shape: torch.Size([3, 224, 224])\n",
            "epoch 1 100.0% test finish\n",
            "Epoch: 1/1, Train loss: 2.483809, Test loss: 0.572972, Accuracy: 0.00\n",
            "Epoch 1 Elapsed time is 0:00:02\n",
            "Total Elapsed time is 0:00:02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "20iKmhA22Iuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learnt_model = create_model(input_channel, True)\n",
        "print(transfer_learnt_model.eval())"
      ],
      "metadata": {
        "id": "0KlDO1moeSWe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "035bf8bb-ee49-447d-d047-f5f6329c08da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3d771be9ff43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransfer_learnt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_learnt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: create_model() takes from 1 to 2 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params_transfer_learning = sum(param.numel() for param in transfer_learnt_model.parameters() if param.requires_grad)\n",
        "print(total_params_transfer_learning)"
      ],
      "metadata": {
        "id": "90ti5OVJfyCD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "f2aba505-7c1b-4066-912d-47aaa6698922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-338d6927b444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal_params_transfer_learning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransfer_learnt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_params_transfer_learning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transfer_learnt_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_test_losses = []\n",
        "\n",
        "def train_transfer_learnt_model():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # loss_function=loss_fn\n",
        "\n",
        "    print(\"start train\")\n",
        "    print(\"train size:\", train_size)\n",
        "    print(\"test size:\", test_size)\n",
        "\n",
        "    trained_number = 0\n",
        "    training_loss = 0\n",
        "    total_start = time.time()\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "      epoch_start = time.time()\n",
        "\n",
        "      for i, data in enumerate(train_dataloader):\n",
        "        # i_start = time.time()\n",
        "        \n",
        "        # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.type(torch.LongTensor) \n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # process_time = time.time()\n",
        "\n",
        "        # 이전 batch에서 계산된 가중치를 초기화\n",
        "        optimizer.zero_grad() \n",
        "        # forward + back propagation 연산\n",
        "        outputs = transfer_learnt_model(inputs).squeeze()\n",
        "        \n",
        "        # i_loss = time.time()\n",
        "\n",
        "        # train_loss = loss_fn(outputs.to(torch.float32), labels.to(torch.float32))\n",
        "        train_loss = getLoss(outputs, labels)\n",
        "\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        training_loss += train_loss.item()\n",
        "        trained_number += labels.size(0)\n",
        "\n",
        "        # i_end = time.time()\n",
        "\n",
        "        # print(\"process_time:\", process_time - i_start, \"pred_time:\", i_loss - process_time,\"loss_time:\",i_end - i_loss)\n",
        "        \n",
        "        # if i % 20 == 0:\n",
        "        #   print(\"i is:\", i)\n",
        "        \n",
        "        if i % 50 == 0:\n",
        "          print(f\"epoch {epoch}: {(trained_number/train_size)*100}% train finish\")\n",
        "        # break\n",
        "    \n",
        "      print(f\"epoch {epoch} train finish\")\n",
        "      # test accuracy 계산\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      # test_loss_list = list()\n",
        "      test_loss_total = 0\n",
        "\n",
        "      for i, data in enumerate(test_dataloader):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 결과값 연산\n",
        "        outputs = transfer_learnt_model(inputs).squeeze()\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (abs(outputs - labels)<0.5).sum().item()\n",
        "        # test_loss = loss_fn(outputs.to(torch.float32), labels.to(torch.float32)).item()\n",
        "        test_loss = getLoss(outputs, labels)\n",
        "\n",
        "        # test_loss_list.append(test_loss)\n",
        "        test_loss_total += test_loss\n",
        "\n",
        "        all_test_losses.append(test_loss)\n",
        "        \n",
        "        # Calculating random MSE:\n",
        "\n",
        "\n",
        "        if i%20==0:\n",
        "          print(f\"epoch {epoch} {total/test_size*100}% test finish\")\n",
        "        # break\n",
        "\n",
        "      # 학습 결과 출력\n",
        "      # print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch, num_epochs, train_loss.item(), sum(test_loss_list)/len(test_loss_list), 100*correct/total))\n",
        "      print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch, num_epochs, train_loss.item(), test_loss_total/labels.size(0), 100*correct/total))\n",
        "\n",
        "      epoch_elapsed_time = time.time() - epoch_start\n",
        "      epoch_elapsed_time_list = str(datetime.timedelta(seconds=epoch_elapsed_time)).split(\".\")\n",
        "      total_elapsed_time = time.time() - total_start\n",
        "      total_elapsed_time_list = str(datetime.timedelta(seconds=total_elapsed_time)).split(\".\")\n",
        "      print(f\"Epoch {epoch} Elapsed time is {epoch_elapsed_time_list[0]}\")  \n",
        "      print(f\"Total Elapsed time is {total_elapsed_time_list[0]}\")  "
      ],
      "metadata": {
        "id": "XepSHSvSeqh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NL-ezWkIW6_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
