{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnbIaWdHTFuC"
      },
      "source": [
        "### 이 파일이 이미지로 점수 예측하는 코드입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsLThwa3wzCn"
      },
      "source": [
        "# 0. 실행할 부분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5uikNndWW_9T"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nfs/home/dailyavenger/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# torchvision 관련 라이브러리 import\n",
        "\n",
        "from torchvision import utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x8E-xwbW_Qt",
        "outputId": "8524635b-89fb-44b1-e667-3b54bf543672"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3gRUgpEW9cq",
        "outputId": "9d0a8001-ff71-48eb-b4cb-8554ca0d5d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonlines in ./.local/lib/python3.9/site-packages (3.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3/dist-packages (from jsonlines) (20.3.0)\n",
            "Requirement already satisfied: pdf2image in ./.local/lib/python3.9/site-packages (1.16.0)\n",
            "Requirement already satisfied: pillow in ./.local/lib/python3.9/site-packages (from pdf2image) (9.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install jsonlines\n",
        "!pip install pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0wgRUMyyW9je"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XW5zuXp1W9nc"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import jsonlines\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq9kUAavw9Gi"
      },
      "source": [
        "#1. 데이터셋 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xw36Jb0yW9s-"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import cv2\n",
        "\n",
        "class PaperDataSet(Dataset):\n",
        "    def __init__(self, overall_image_path, transform=None):\n",
        "        print(\"initialize data sets\")\n",
        "        self.transform = transform\n",
        "        rating_dict = {}\n",
        "        self.image_list = list()\n",
        "        self.score_list = list()\n",
        "        years = [\"2021\"]\n",
        "        lst_ = [ \"UH-cmocLJC\", \"mNtmhaDkAr\",  \"UiLl8yjh57\",  \"kB8DkEKSDH\", \"cL4wkyoxyDJ\"]\n",
        "        for year in years:\n",
        "            cnt = 0\n",
        "            year_image_path = overall_image_path\n",
        "            # year_image_path = overall_image_path+\"iclr\"+year+\"/\"\n",
        "            # *********** 경로 수정 ***********\n",
        "            with jsonlines.open(f\"iclr{year}_metadata.jsonl\") as read_file:\n",
        "                for line in read_file.iter():\n",
        "                    rating_dict[line['forum']] = line['rating']\n",
        "            input_paths = os.listdir(year_image_path)\n",
        "            for one_file_image_path in tqdm(input_paths, desc=\"make data set\"):\n",
        "                if one_file_image_path not in lst_:\n",
        "                  image_path = year_image_path + one_file_image_path + \"/\"\n",
        "                  before_add_size = len(self.image_list)\n",
        "                  self.image_list.extend(glob.glob(image_path + \"*.bin\")) # glob: 폴더 내의 파일 찾아줌\n",
        "                  rating = rating_dict[one_file_image_path]\n",
        "                  self.score_list.extend([rating] * (len(self.image_list)-before_add_size))\n",
        "                  cnt += len(self.image_list)-before_add_size\n",
        "                else:\n",
        "                  print(one_file_image_path, \"is in lst_\")\n",
        "            print(f\"{year}: {cnt}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_list[idx]\n",
        "        label = self.score_list[idx]\n",
        "        binary_file = image_path   # binary_file = dataset/image/iclr2021/_0kaDkv3dVf/3.bin \n",
        "        with open(binary_file, 'rb') as f:\n",
        "            data = f.read()\n",
        "        encoded_img = np.fromstring(data, dtype=np.uint8)\n",
        "        img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR) \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        \n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cSfWpocEW9xt"
      },
      "outputs": [],
      "source": [
        "image_path =  \"../wngusrud27/dataset/image/iclr2021/\" \n",
        "image_path2 =  \"temp/\" \n",
        "dataset_file_name = 'iclr2021_dataset.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Op-IvCLdxQAD"
      },
      "outputs": [],
      "source": [
        "#zip_path = image_path + \"iclr2021_binary.zip\"\n",
        "\n",
        "#!mkdir binary\n",
        "\n",
        "#!cp {zip_path} ./iclr2021.zip\n",
        "\n",
        "#!unzip -q ./iclr2021.zip -d ./binary/ \n",
        "\n",
        "#!rm ./iclr2021.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cgKR9l_DXcJ6"
      },
      "outputs": [],
      "source": [
        "def make_save_data_set(image_path2, dataset_file_name):\n",
        "  print(\"start to make data set\")\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "  dataset = PaperDataSet(image_path, transform=transform)\n",
        "  print(f\"data set length: {dataset.__len__()}\")\n",
        "\n",
        "  torch.save(dataset, image_path2 + dataset_file_name)\n",
        "  print(\"save data sets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt1_lnn8XcMi",
        "outputId": "1c57eee0-2be1-4be8-93ba-45e227f5cddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start to make data set\n",
            "initialize data sets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "make data set:  18%|█▊        | 458/2594 [00:00<00:00, 4579.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kB8DkEKSDH is in lst_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "make data set:  56%|█████▌    | 1440/2594 [00:00<00:00, 4848.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UiLl8yjh57 is in lst_\n",
            "mNtmhaDkAr is in lst_\n",
            "UH-cmocLJC is in lst_\n",
            "cL4wkyoxyDJ is in lst_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "make data set: 100%|██████████| 2594/2594 [00:00<00:00, 4927.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021: 23301\n",
            "data set length: 23301\n",
            "save data sets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#image_path =  \"./binary/\" \n",
        "make_save_data_set(image_path2, dataset_file_name)\n",
        "# data_set_usage_ex(dataset_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEqyEffNZy6k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WjyhkPoaxNj",
        "outputId": "6f0f6ae7-cb39-4278-b73a-e611857b9fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train size: 18639\n",
            "test size: 4662\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "dataset = torch.load(image_path2+dataset_file_name)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "print(\"train size:\", train_size-1)\n",
        "\n",
        "test_size = len(dataset) - train_size\n",
        "print(\"test size:\", test_size+1)\n",
        "# validation \n",
        "train_dataset, test_dataset = random_split(dataset, [train_size-1,test_size+1])\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvjr_4qUNeYW"
      },
      "source": [
        "# 2 모델 생성,하이퍼 파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_UegSgy0NMSS"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=False).to(device) # true 옵션으로 사전 학습된 모델을 로드\n",
        "\n",
        "# transfer learning 사용 시 추가 \n",
        "# if using_transfer_learning:|\n",
        "#   for param in resnet50.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "model = nn.Sequential(\n",
        "    resnet50,\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(1000, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1)\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KaZHNA_HNk7b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "lr = 0.0001\n",
        "num_epochs = 10\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "loss_function = nn.MSELoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9CHLTVscNqcv"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'num_epochs':num_epochs,\n",
        "    'optimizer':optimizer,\n",
        "    'loss_function':loss_function,\n",
        "    'train_dataloader':train_dataloader,\n",
        "    'test_dataloader': test_dataloader,\n",
        "    'device':device\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqYfFv_KknpU"
      },
      "source": [
        "# 3. 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3HgavN8RgIgR"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWBymtOu8a8E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "W2ZnqIjCNqfQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "from numpy import vstack\n",
        "\n",
        "def train(model, params):\n",
        "  total_start = time.time()\n",
        "  loss_function=params[\"loss_function\"]\n",
        "  train_dataloader=params[\"train_dataloader\"]\n",
        "  test_dataloader=params[\"test_dataloader\"]\n",
        "  device=params[\"device\"]\n",
        "\n",
        "  print(\"start train\")\n",
        "  print(\"train size:\", train_size)\n",
        "  print(\"test size:\", test_size)\n",
        "  for epoch in range(0, num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    epoch_start = time.time()\n",
        "    trained_number = 0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        \n",
        "        # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.type(torch.FloatTensor) \n",
        "      labels = labels.to(device)\n",
        "        \n",
        "        # 이전 batch에서 계산된 가중치를 초기화\n",
        "      optimizer.zero_grad() \n",
        "        # forward + back propagation 연산\n",
        "      outputs = model(inputs).squeeze()\n",
        "      train_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32))\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "      trained_number += labels.size(0)\n",
        "        \n",
        "      if i%100==0:\n",
        "        print(f\"epoch {epoch+1} {trained_number/train_size*100}% train finish\")\n",
        "    print(f\"epoch {epoch+1} train finish\") \n",
        "\n",
        "\n",
        "    model.eval()\n",
        "      # test accuracy 계산\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss = 0\n",
        "    correct2 = 0 \n",
        "\n",
        "    for i, data in enumerate(test_dataloader, 0):\n",
        "        \n",
        "      inputs, labels = data        \n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.type(torch.FloatTensor) \n",
        "      labels = labels.to(device)\n",
        "        \n",
        "\n",
        "        # 결과값 연산\n",
        "      outputs = model(inputs).squeeze()\n",
        "      i_batch_size = labels.size(0)\n",
        "      total += i_batch_size\n",
        "      correct += (abs(outputs - labels)<0.5).sum().item() # 변경될 수 있음 \n",
        "      correct2 += (abs(outputs - labels)).sum().item()\n",
        "      test_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32)).item()\n",
        "      loss += i_batch_size * test_loss\n",
        "      if i%50==0:\n",
        "        print(f\"epoch {epoch+1} {total/test_size*100}% test finish\")\n",
        "        # break\n",
        "\n",
        "      # 학습 결과 출력\n",
        "    print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f, difference: %.6f' %(epoch+1, num_epochs, train_loss.item(), loss/total, 100*correct/total, correct2/total)) #, correct2/total\n",
        "\n",
        "    epoch_elapsed_time = time.time() - epoch_start\n",
        "    epoch_elapsed_time_list = str(datetime.timedelta(seconds=epoch_elapsed_time)).split(\".\")\n",
        "    total_elapsed_time = time.time() - total_start\n",
        "    total_elapsed_time_list = str(datetime.timedelta(seconds=total_elapsed_time)).split(\".\")\n",
        "    print(f\"Epoch {epoch+1} Elapsed time is {epoch_elapsed_time_list[0]}\")  \n",
        "    print(f\"Total Elapsed time is {total_elapsed_time_list[0]}\")  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-0RVcRz9hyd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmAGMDr2Nqhv",
        "outputId": "07a671f2-afa7-4d40-a140-07836aa98218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start train\n",
            "train size: 18640\n",
            "test size: 4661\n",
            "epoch 1 0.08583690987124463% train finish\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2778145/1007042753.py:44: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  encoded_img = np.fromstring(data, dtype=np.uint8)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 8.669527896995708% train finish\n",
            "epoch 1 17.253218884120173% train finish\n",
            "epoch 1 25.836909871244636% train finish\n",
            "epoch 1 34.4206008583691% train finish\n",
            "epoch 1 43.00429184549356% train finish\n",
            "epoch 1 51.58798283261803% train finish\n",
            "epoch 1 60.17167381974249% train finish\n",
            "epoch 1 68.75536480686695% train finish\n",
            "epoch 1 77.33905579399142% train finish\n",
            "epoch 1 85.92274678111588% train finish\n",
            "epoch 1 94.50643776824035% train finish\n",
            "epoch 1 train finish\n",
            "epoch 1 0.3432739755417292% test finish\n",
            "epoch 1 17.50697275262819% test finish\n",
            "epoch 1 34.67067152971465% test finish\n",
            "epoch 1 51.83437030680111% test finish\n",
            "epoch 1 68.99806908388759% test finish\n",
            "epoch 1 86.16176786097404% test finish\n",
            "Epoch: 1/10, Train loss: 0.495793, Test loss: 0.542289, Accuracy: 53.78, difference: 0.571372\n",
            "Epoch 1 Elapsed time is 0:01:24\n",
            "Total Elapsed time is 0:01:24\n",
            "epoch 2 0.08583690987124463% train finish\n",
            "epoch 2 8.669527896995708% train finish\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/nfs/home/dailyavenger/0519 결과도출.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000024vscode-remote?line=1'>2</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()              \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000024vscode-remote?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000024vscode-remote?line=3'>4</a>\u001b[0m train(model, params)\n",
            "\u001b[1;32m/nfs/home/dailyavenger/0519 결과도출.ipynb Cell 23'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000022vscode-remote?line=17'>18</a>\u001b[0m epoch_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000022vscode-remote?line=18'>19</a>\u001b[0m trained_number \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000022vscode-remote?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader, \u001b[39m0\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000022vscode-remote?line=20'>21</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000022vscode-remote?line=21'>22</a>\u001b[0m     \u001b[39m# train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000022vscode-remote?line=22'>23</a>\u001b[0m   inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000022vscode-remote?line=23'>24</a>\u001b[0m   inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataset.py:471\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=468'>469</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=469'>470</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> <a href='file:///nfs/home/dailyavenger/.local/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=470'>471</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
            "\u001b[1;32m/nfs/home/dailyavenger/0519 결과도출.ipynb Cell 9'\u001b[0m in \u001b[0;36mPaperDataSet.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000008vscode-remote?line=39'>40</a>\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_list[idx]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000008vscode-remote?line=40'>41</a>\u001b[0m binary_file \u001b[39m=\u001b[39m image_path   \u001b[39m# binary_file = dataset/image/iclr2021/_0kaDkv3dVf/3.bin \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000008vscode-remote?line=41'>42</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(binary_file, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000008vscode-remote?line=42'>43</a>\u001b[0m     data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22616373797330332e796f6e7365692e61632e6b72222c2275736572223a226461696c796176656e676572227d/nfs/home/dailyavenger/0519%20%EA%B2%B0%EA%B3%BC%EB%8F%84%EC%B6%9C.ipynb#ch0000008vscode-remote?line=43'>44</a>\u001b[0m encoded_img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfromstring(data, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()              \n",
        "torch.cuda.empty_cache()\n",
        "train(model, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ilaHF08p9iqv",
        "outputId": "9052e59e-faaf-405d-cc85-dc61502f7cbf"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (1203984595.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Input \u001b[0;32mIn [17]\u001b[0;36m\u001b[0m\n\u001b[0;31m    +=1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "+=1\n",
        "\n",
        "torch.save(model.state_dict(), \"temp/model1\" )\n",
        "\n",
        "torch.save(model, \"temp2/model2\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc7CClaJ92H_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpygeWT-F2Nb"
      },
      "source": [
        "## 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRniceI5F31-"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import cv2\n",
        "class TestDataSet(Dataset):\n",
        "    def __init__(self, overall_image_path, transform=None):\n",
        "        print(\"initialize data sets\")\n",
        "        self.transform = transform\n",
        "        rating_dict = {}\n",
        "        self.image_list = list()\n",
        "        self.score_list = list()\n",
        "        cnt = 0\n",
        "        year_image_path = overall_image_path\n",
        "        # year_image_path = overall_image_path+\"iclr\"+year+\"/\"\n",
        "        with jsonlines.open(f\"drive/Shareddrives/소종-논문/iclr2021_metadata.jsonl\") as read_file:\n",
        "            for line in read_file.iter():\n",
        "                rating_dict[line['forum']] = line['rating']\n",
        "        input_paths = os.listdir(year_image_path)\n",
        "        input_paths.sort()\n",
        "        for one_file_image_path in tqdm(input_paths, desc=\"make data set\"):\n",
        "            image_path = year_image_path + one_file_image_path + \"/\"\n",
        "            before_add_size = len(self.image_list)\n",
        "            imgs = glob.glob(image_path + \"1.bin\")\n",
        "            imgs.sort()\n",
        "            self.image_list.extend(imgs) # glob: 폴더 내의 파일 찾아줌\n",
        "            rating = rating_dict[one_file_image_path]\n",
        "            self.score_list.extend([rating] * (len(self.image_list)-before_add_size))\n",
        "            cnt += len(self.image_list)-before_add_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_list[idx]\n",
        "        label = self.score_list[idx]\n",
        "        binary_file = image_path   # binary_file = dataset/image/iclr2021/_0kaDkv3dVf/3.bin \n",
        "        with open(binary_file, 'rb') as f:\n",
        "            data = f.read()\n",
        "        encoded_img = np.fromstring(data, dtype=np.uint8)\n",
        "        img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR) \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def img_list(self):\n",
        "      print(self.image_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PDBRIS7F34A"
      },
      "outputs": [],
      "source": [
        "image_path = \"drive/Shareddrives/소종-논문/test/binary/occlusion/\" \n",
        "dataset_file_name = 'iclr2021_dataset_test.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofxU100mF36Z"
      },
      "outputs": [],
      "source": [
        "def test_make_save_data_set(image_path, dataset_file_name):\n",
        "  print(\"start to make data set\")\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "  dataset = TestDataSet(image_path, transform=transform)\n",
        "  print(f\"data set length: {dataset.__len__()}\")\n",
        "\n",
        "  torch.save(dataset, dataset_file_name)\n",
        "  print(\"save data sets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2yUeA3f9kGd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huVmvsZgF38Y",
        "outputId": "271add82-0b93-4286-a2a0-0d17052d1a3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start to make data set\n",
            "initialize data sets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "make data set: 100%|██████████| 5/5 [00:00<00:00, 940.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data set length: 45\n",
            "save data sets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_make_save_data_set(image_path, dataset_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crqiq-0BF3-V",
        "outputId": "43ad5bca-7c7b-4e7a-f05b-b7c6e2029e76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test size: 45\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "dataset = torch.load(dataset_file_name)\n",
        "\n",
        "test_size = len(dataset)\n",
        "print(\"test size:\", test_size)\n",
        "# validation \n",
        "\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-zjIOU1F4Ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgRShB7jF4Cm"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "from numpy import vstack\n",
        "\n",
        "def test(model, params):\n",
        "    total_start = time.time()\n",
        "    loss_function=params[\"loss_function\"]\n",
        "    test_dataloader=dataloader\n",
        "    device=params[\"device\"]\n",
        "\n",
        "    print(\"start train\")\n",
        "    print(\"test size:\", test_size)\n",
        "\n",
        "    # test accuracy 계산\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss = 0\n",
        "    model.eval()\n",
        "    \n",
        "    for i, data in enumerate(test_dataloader, 0):\n",
        "      print(\"i:\", i)\n",
        "      \n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.type(torch.FloatTensor) \n",
        "      labels = labels.to(device)\n",
        "\n",
        "      print(\"size:\",labels.size(0))\n",
        "      print(\"label:\", labels)\n",
        "      \n",
        "\n",
        "      # 결과값 연산\n",
        "      outputs = model(inputs).squeeze()\n",
        "      print(\"output:\", outputs)\n",
        "      i_batch_size = labels.size(0)\n",
        "      total += i_batch_size\n",
        "      correct += (abs(outputs - labels)<0.5).sum().item() # 변경될 수 있음 \n",
        "      test_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32)).item()\n",
        "      loss += i_batch_size * test_loss\n",
        "\n",
        "      # 학습 결과 출력\n",
        "    print('Test loss: %.6f, Accuracy: %.2f' %(loss/total, 100*correct/total))\n",
        "\n",
        "    total_elapsed_time = time.time() - total_start\n",
        "    total_elapsed_time_list = str(datetime.timedelta(seconds=total_elapsed_time)).split(\".\")\n",
        "    print(f\"Total Elapsed time is {total_elapsed_time_list[0]}\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOfSetI1F4Ew",
        "outputId": "dc92c833-8d06-4c79-a096-a1876d93d8af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start train\n",
            "test size: 45\n",
            "i: 0\n",
            "size: 32\n",
            "label: tensor([8.7500, 8.7500, 8.7500, 8.7500, 8.7500, 8.7500, 8.7500, 8.7500, 8.7500,\n",
            "        5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000, 5.5000,\n",
            "        2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000,\n",
            "        4.0000, 4.0000, 4.0000, 4.0000, 4.0000], device='cuda:0')\n",
            "output: tensor([6.5816, 6.5845, 6.5476, 6.7172, 6.5774, 6.7502, 6.5787, 6.6212, 6.6677,\n",
            "        5.2512, 4.5495, 5.4114, 5.3056, 5.1830, 4.2590, 5.1306, 4.4159, 5.0974,\n",
            "        4.9216, 4.9011, 4.5559, 5.0236, 4.7439, 5.2108, 4.7982, 5.3017, 4.9362,\n",
            "        4.7339, 4.6832, 5.0069, 4.9728, 4.8730], device='cuda:0',\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i: 1\n",
            "size: 13\n",
            "label: tensor([4., 4., 4., 4., 7., 7., 7., 7., 7., 7., 7., 7., 7.], device='cuda:0')\n",
            "output: tensor([5.2232, 4.7544, 4.4490, 4.9124, 6.6159, 6.6060, 6.7244, 6.4929, 6.6800,\n",
            "        6.5359, 6.5436, 6.2699, 6.6201], device='cuda:0',\n",
            "       grad_fn=<SqueezeBackward0>)\n",
            "Test loss: 2.917464, Accuracy: 31.11\n",
            "Total Elapsed time is 0:00:00\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "test(model, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olgosH4f-cnH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ofBofdF0Cl"
      },
      "source": [
        "## 안쓰는 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zxw_uyDk52_"
      },
      "outputs": [],
      "source": [
        "lst = list()\n",
        "with jsonlines.open(\"iclr2021_metadata.jsonl\") as read_file:\n",
        "  for line in read_file.iter():\n",
        "    lst.append(float(line['rating']))\n",
        "avg = sum(lst)/len(lst)\n",
        "print(avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbnsurcjCaHp"
      },
      "outputs": [],
      "source": [
        "avg_lst = [avg] * len(lst)\n",
        "loss_function = nn.MSELoss()\n",
        "test_loss = loss_function(torch.Tensor(lst).to(torch.float32), torch.Tensor(avg_lst).to(torch.float32)).item()\n",
        "print(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddCq-3vtBYkJ"
      },
      "outputs": [],
      "source": [
        "total = 0\n",
        "loss = 0\n",
        "for i, data in enumerate(test_dataloader, 0):\n",
        "  inputs, labels = data\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.type(torch.FloatTensor) \n",
        "  labels = labels.to(device)\n",
        "  \n",
        "  i_batch_size = labels.size(0)\n",
        "  outputs = [avg] * i_batch_size\n",
        "  outputs = torch.Tensor(outputs).to(device)\n",
        "  total += i_batch_size\n",
        "  test_loss = loss_function(outputs.to(torch.float32), labels.to(torch.float32)).item()\n",
        "  loss += i_batch_size * test_loss\n",
        "\n",
        "print('loss: %.6f' %(loss/total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gxavH25CBz3"
      },
      "outputs": [],
      "source": [
        " from torchvision import models\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=True) # true 옵션으로 사전 학습된 모델을 로드\n",
        "\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model2 = nn.Sequential(\n",
        "    resnet50,\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(1000, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1)\n",
        ").to(device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0519_capstone_resnet50 (1).ipynb의 사본",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
